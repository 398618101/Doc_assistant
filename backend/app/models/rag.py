#!/usr/bin/env python3
"""
RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ) ç›¸å…³æ•°æ®æ¨¡å‹
"""
from typing import List, Optional, Dict, Any, Union
from pydantic import BaseModel, Field
from datetime import datetime
from enum import Enum


class ChatRole(str, Enum):
    """å¯¹è¯è§’è‰²æšä¸¾"""
    USER = "user"
    ASSISTANT = "assistant"
    SYSTEM = "system"


class ResponseMode(str, Enum):
    """å“åº”æ¨¡å¼æšä¸¾"""
    STREAMING = "streaming"  # æµå¼å“åº”
    COMPLETE = "complete"    # å®Œæ•´å“åº”


class ContextStrategy(str, Enum):
    """ä¸Šä¸‹æ–‡æ„å»ºç­–ç•¥"""
    SIMPLE = "simple"        # ç®€å•æ‹¼æ¥
    RANKED = "ranked"        # æŒ‰ç›¸å…³æ€§æ’åº
    SUMMARIZED = "summarized"  # æ‘˜è¦å‹ç¼©
    HIERARCHICAL = "hierarchical"  # å±‚æ¬¡åŒ–ç»„ç»‡


class DocumentSource(BaseModel):
    """æ–‡æ¡£æ¥æºä¿¡æ¯"""
    document_id: str
    filename: str
    chunk_id: str
    page_number: Optional[int] = None
    section: Optional[str] = None
    relevance_score: float
    content_preview: str  # å†…å®¹é¢„è§ˆï¼ˆå‰100å­—ç¬¦ï¼‰


class ChatMessage(BaseModel):
    """å¯¹è¯æ¶ˆæ¯æ¨¡å‹"""
    role: ChatRole
    content: str
    timestamp: datetime = Field(default_factory=datetime.now)
    metadata: Optional[Dict[str, Any]] = None


class RetrievalContext(BaseModel):
    """æ£€ç´¢ä¸Šä¸‹æ–‡æ¨¡å‹"""
    query: str
    retrieved_chunks: List[Dict[str, Any]]
    total_chunks: int
    retrieval_time: float
    context_length: int
    sources: List[DocumentSource]  # æ¥æºæ–‡æ¡£ä¿¡æ¯


class ChatRequest(BaseModel):
    """èŠå¤©è¯·æ±‚æ¨¡å‹"""
    message: str = Field(..., description="ç”¨æˆ·æ¶ˆæ¯")
    conversation_id: Optional[str] = Field(None, description="å¯¹è¯IDï¼Œç”¨äºä¿æŒä¸Šä¸‹æ–‡")
    response_mode: ResponseMode = Field(default=ResponseMode.STREAMING, description="å“åº”æ¨¡å¼")
    
    # æ£€ç´¢é…ç½®
    enable_retrieval: bool = Field(default=True, description="æ˜¯å¦å¯ç”¨æ–‡æ¡£æ£€ç´¢")
    max_retrieved_chunks: int = Field(default=5, ge=1, le=20, description="æœ€å¤§æ£€ç´¢æ–‡æ¡£å—æ•°")
    similarity_threshold: float = Field(default=0.6, ge=0.0, le=1.0, description="ç›¸ä¼¼åº¦é˜ˆå€¼")
    
    # ä¸Šä¸‹æ–‡é…ç½®
    context_strategy: ContextStrategy = Field(default=ContextStrategy.RANKED, description="ä¸Šä¸‹æ–‡æ„å»ºç­–ç•¥")
    max_context_length: int = Field(default=4000, ge=500, le=8000, description="æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦")
    include_chat_history: bool = Field(default=True, description="æ˜¯å¦åŒ…å«å¯¹è¯å†å²")
    max_history_messages: int = Field(default=10, ge=0, le=50, description="æœ€å¤§å†å²æ¶ˆæ¯æ•°")
    
    # ç”Ÿæˆé…ç½®
    temperature: float = Field(default=0.7, ge=0.0, le=2.0, description="ç”Ÿæˆæ¸©åº¦")
    max_tokens: int = Field(default=1000, ge=50, le=4000, description="æœ€å¤§ç”Ÿæˆtokenæ•°")
    stream: bool = Field(default=True, description="æ˜¯å¦æµå¼è¾“å‡º")


class ChatResponse(BaseModel):
    """èŠå¤©å“åº”æ¨¡å‹"""
    success: bool
    message: str
    conversation_id: str
    response_time: float
    
    # æ£€ç´¢ä¿¡æ¯
    retrieval_context: Optional[RetrievalContext] = None
    sources_used: List[Dict[str, Any]] = Field(default_factory=list)
    
    # ç”Ÿæˆä¿¡æ¯
    tokens_used: Optional[int] = None
    finish_reason: Optional[str] = None
    
    # å…ƒæ•°æ®
    timestamp: datetime = Field(default_factory=datetime.now)
    model_used: Optional[str] = None
    error_message: Optional[str] = None


class StreamingChatResponse(BaseModel):
    """æµå¼èŠå¤©å“åº”æ¨¡å‹"""
    conversation_id: str
    chunk: str
    is_final: bool = False
    
    # ä»…åœ¨æœ€ç»ˆå—ä¸­åŒ…å«
    retrieval_context: Optional[RetrievalContext] = None
    sources_used: List[Dict[str, Any]] = Field(default_factory=list)
    total_tokens: Optional[int] = None
    finish_reason: Optional[str] = None


class ConversationHistory(BaseModel):
    """å¯¹è¯å†å²æ¨¡å‹"""
    conversation_id: str
    messages: List[ChatMessage]
    created_at: datetime = Field(default_factory=datetime.now)
    updated_at: datetime = Field(default_factory=datetime.now)
    metadata: Optional[Dict[str, Any]] = None


class RAGConfig(BaseModel):
    """RAGé…ç½®æ¨¡å‹"""
    # æ£€ç´¢é…ç½®
    default_retrieval_count: int = Field(default=5, description="é»˜è®¤æ£€ç´¢æ–‡æ¡£æ•°")
    default_similarity_threshold: float = Field(default=0.3, description="é»˜è®¤ç›¸ä¼¼åº¦é˜ˆå€¼(é™ä½ä»¥è·å¾—æ›´å¤šç»“æœ)")
    enable_hybrid_search: bool = Field(default=True, description="å¯ç”¨æ··åˆæœç´¢")
    
    # ä¸Šä¸‹æ–‡é…ç½®
    max_context_tokens: int = Field(default=4000, description="æœ€å¤§ä¸Šä¸‹æ–‡tokenæ•°")
    context_overlap_ratio: float = Field(default=0.1, description="ä¸Šä¸‹æ–‡é‡å æ¯”ä¾‹")
    
    # ç”Ÿæˆé…ç½®
    default_temperature: float = Field(default=0.7, description="é»˜è®¤ç”Ÿæˆæ¸©åº¦")
    default_max_tokens: int = Field(default=1000, description="é»˜è®¤æœ€å¤§ç”Ÿæˆtokenæ•°")
    
    # å¯¹è¯é…ç½®
    max_conversation_history: int = Field(default=50, description="æœ€å¤§å¯¹è¯å†å²æ•°")
    conversation_timeout_hours: int = Field(default=24, description="å¯¹è¯è¶…æ—¶æ—¶é—´(å°æ—¶)")
    
    # ç³»ç»Ÿæç¤ºè¯
    system_prompt: str = Field(
        default="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ™ºèƒ½æ–‡æ¡£åŠ©ç†ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è¦æ±‚å›ç­”ç”¨æˆ·é—®é¢˜ï¼š

## ğŸ¯ æ ¸å¿ƒè¦æ±‚
1. **ä»…åŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”**ï¼Œä¸è¦æ·»åŠ æ–‡æ¡£å¤–çš„ä¿¡æ¯
2. **å›ç­”è¦ç®€æ´æ˜äº†**ï¼Œé¿å…é‡å¤å’Œå†—ä½™
3. **ä½¿ç”¨ä¸­æ–‡å›ç­”**ï¼Œä¿æŒè¯­è¨€æµç•…è‡ªç„¶
4. **ç›´æ¥å›ç­”é—®é¢˜**ï¼Œä¸è¦è¿‡åº¦è§£é‡Š

## ğŸ“‹ å›ç­”æ ¼å¼
### å½“æœ‰ç›¸å…³æ–‡æ¡£å†…å®¹æ—¶ï¼š
- ç›´æ¥æå–æ–‡æ¡£ä¸­çš„å…³é”®ä¿¡æ¯
- ç”¨ç®€æ´çš„è¯­è¨€ç»„ç»‡ç­”æ¡ˆ
- å¦‚æœ‰åˆ—è¡¨ä¿¡æ¯ï¼Œä½¿ç”¨é¡¹ç›®ç¬¦å·
- é¿å…é‡å¤ç›¸åŒçš„è¯æ±‡æˆ–çŸ­è¯­

### å½“æ²¡æœ‰ç›¸å…³æ–‡æ¡£å†…å®¹æ—¶ï¼š
- ç®€å•è¯´æ˜ï¼š"æ ¹æ®æä¾›çš„æ–‡æ¡£å†…å®¹ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
- ä¸è¦çŒœæµ‹æˆ–æ·»åŠ é¢å¤–å†…å®¹

## âš ï¸ ä¸¥æ ¼ç¦æ­¢
- é‡å¤ä½¿ç”¨ç›¸åŒè¯æ±‡ï¼ˆå¦‚"æå–"ã€"extract"ç­‰ï¼‰
- ç”Ÿæˆæ— æ„ä¹‰çš„é‡å¤å†…å®¹
- æ·»åŠ æ–‡æ¡£ä¸­ä¸å­˜åœ¨çš„ä¿¡æ¯
- ä½¿ç”¨è¿‡äºå¤æ‚çš„è¡¨è¿°

è¯·åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹ç®€æ´å‡†ç¡®åœ°å›ç­”ç”¨æˆ·é—®é¢˜ï¼š""",
        description="ç®€åŒ–ä¼˜åŒ–çš„ç³»ç»Ÿæç¤ºè¯"
    )


class QueryAnalysis(BaseModel):
    """æŸ¥è¯¢åˆ†æç»“æœ"""
    original_query: str
    intent: str  # é—®ç­”ã€æœç´¢ã€æ‘˜è¦ç­‰
    keywords: List[str]
    entities: List[str]
    query_type: str  # factual, analytical, creativeç­‰
    complexity_score: float  # 0-1ï¼ŒæŸ¥è¯¢å¤æ‚åº¦
    requires_context: bool  # æ˜¯å¦éœ€è¦ä¸Šä¸‹æ–‡
    suggested_retrieval_count: int  # å»ºè®®æ£€ç´¢æ•°é‡


class ContextWindow(BaseModel):
    """ä¸Šä¸‹æ–‡çª—å£æ¨¡å‹"""
    system_prompt: str
    conversation_history: List[ChatMessage]
    retrieved_context: str
    total_tokens: int
    context_sources: List[DocumentSource]


class RAGMetrics(BaseModel):
    """RAGæ€§èƒ½æŒ‡æ ‡"""
    # è¯·æ±‚ç»Ÿè®¡
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0

    # æ—¶é—´ç»Ÿè®¡
    total_response_time: float = 0.0
    average_response_time: float = 0.0
    avg_retrieval_time: float = 0.0
    avg_generation_time: float = 0.0

    # å…¼å®¹æ—§å­—æ®µ
    query_count: int = 0
    avg_total_time: float = 0.0
    success_rate: float = 1.0
    avg_context_length: int = 0
    avg_response_length: int = 0
    popular_queries: List[Dict[str, Any]] = Field(default_factory=list)
    error_count: int = 0
    last_updated: datetime = Field(default_factory=datetime.now)


class CitationInfo(BaseModel):
    """å¼•ç”¨ä¿¡æ¯"""
    source: DocumentSource
    quoted_text: str
    confidence_score: float
    position_in_response: int  # åœ¨å›ç­”ä¸­çš„ä½ç½®
